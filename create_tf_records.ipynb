{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pykitti\n",
    "from util import *\n",
    "from colmap_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "def _int64_feature(value):\n",
    "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/Users/dewalgupta/Documents/ucsd/lab/data/\"\n",
    "depth_dir = os.path.join(data_dir, 'KITTI/raw/2011_09_30/2011_09_30_drive_0016_sync/post_processed_depth')\n",
    "img_dir = os.path.join(data_dir, 'KITTI/raw/2011_09_30/2011_09_30_drive_0016_sync/image_02/data')\n",
    "category = 'kitti_04'\n",
    "\n",
    "# Build the frame pairs \n",
    "frames = sorted(os.listdir(depth_dir))\n",
    "frames = [f for f in frames if f.endswith(\"png\")]\n",
    "rgb_frames = [category + \"/dense/images/\" + f for f in frames]\n",
    "depth_frames = [category + \"/depth/\" + f for f in frames]\n",
    "rgb_frames = [f.encode('UTF-8') for f in rgb_frames]\n",
    "depth_frames = [f.encode('UTF-8') for f in depth_frames]\n",
    "\n",
    "rgb_frame_1 = np.array(rgb_frames[:-5])\n",
    "rgb_frame_2 = np.array(rgb_frames[5:])\n",
    "depth_frame_1 = np.array(depth_frames[:-5])\n",
    "depth_frame_2 = np.array(depth_frames[5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kitti_dir = os.path.join(data_dir, \"KITTI/raw\")\n",
    "# date = '2011_09_30'\n",
    "# drive = '0016'\n",
    "\n",
    "# data = pykitti.raw(kitti_dir, date, drive)\n",
    "\n",
    "colmap_dir = os.path.join(data_dir, 'colmap/04_color/dense/sparse')\n",
    "points3d = read_points3d_binary(os.path.join(colmap_dir, 'points3D.bin'))\n",
    "images = read_images_binary(os.path.join(colmap_dir, 'images.bin'))\n",
    "camera = read_cameras_binary(os.path.join(colmap_dir, 'cameras.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build the poses\n",
    "poses = [images[f].pose for f in images]\n",
    "\n",
    "# K = data.calib.P_rect_00\n",
    "# K_ci = data.calib.T_cam0_imu @ data.calib.R_rect_00\n",
    "# p0 = data.oxts[0].T_w_imu\n",
    "\n",
    "# for i in range(len(frames)):\n",
    "#     p1 = data.oxts[i].T_w_imu\n",
    "#     rect_pose_f1 = K_ci @ np.linalg.inv(p0) @ p1 @ np.linalg.inv(K_ci)\n",
    "#     T_cw_f1 = np.linalg.inv(rect_pose_f1)\n",
    "#     poses += [T_cw_f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9.99926390e-01  -1.00932212e-02  -6.73365835e-03   1.33008738e-01]\n",
      " [  1.00494935e-02   9.99928399e-01  -6.49643065e-03   1.17375706e-01]\n",
      " [  6.79874613e-03   6.42828259e-03   9.99956226e-01  -6.50992203e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# print(poses[0])\n",
    "# print(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_f1 = np.array(poses[:-5])\n",
    "pose_f2 = np.array(poses[5:])\n",
    "features_dataset = tf.data.Dataset.from_tensor_slices((rgb_frame_1, rgb_frame_2, depth_frame_1, depth_frame_2, pose_f1, pose_f2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(b'kitti_04/dense/images/0000000000.png', b'kitti_04/dense/images/0000000005.png', b'kitti_04/depth/0000000000.png', b'kitti_04/depth/0000000005.png', array([[  9.99926390e-01,  -1.00932212e-02,  -6.73365835e-03,\n",
      "          1.33008738e-01],\n",
      "       [  1.00494935e-02,   9.99928399e-01,  -6.49643065e-03,\n",
      "          1.17375706e-01],\n",
      "       [  6.79874613e-03,   6.42828259e-03,   9.99956226e-01,\n",
      "         -6.50992203e+00],\n",
      "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "          1.00000000e+00]]), array([[  9.99865641e-01,  -1.54760150e-02,  -5.40296983e-03,\n",
      "          1.19036117e-01],\n",
      "       [  1.54497728e-02,   9.99868808e-01,  -4.86540866e-03,\n",
      "          1.02305944e-01],\n",
      "       [  5.47755814e-03,   4.78128030e-03,   9.99973568e-01,\n",
      "         -6.26558787e+00],\n",
      "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "          1.00000000e+00]]))\n"
     ]
    }
   ],
   "source": [
    "# Test the dataset - make sure it looks right\n",
    "\n",
    "iter = features_dataset.make_one_shot_iterator()\n",
    "el = iter.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(el))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_example(rgb_frame_1, rgb_frame_2, depth_frame_1, depth_frame_2, pose1, pose2):\n",
    "    \"\"\"\n",
    "    Creates a tf.Example message ready to be written to a file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a dictionary mapping the feature name to the tf.Example-compatible\n",
    "    # data type.\n",
    "\n",
    "    feature = {\n",
    "      'rgb_fname_1': _bytes_feature(rgb_frame_1),\n",
    "      'rgb_fname_2': _bytes_feature(rgb_frame_2),\n",
    "      'depth_fname_1': _bytes_feature(depth_frame_1),\n",
    "      'depth_fname_2': _bytes_feature(depth_frame_2),\n",
    "      'pose1': _float_feature(np.reshape(pose1, (-1))),\n",
    "      'pose2': _float_feature(np.reshape(pose2, (-1))),\n",
    "    }\n",
    "    \n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString()\n",
    "\n",
    "\n",
    "def dataset_generator(ds, sess):\n",
    "    iterator = ds.make_one_shot_iterator()\n",
    "    next_row = iterator.get_next()\n",
    "   \n",
    "    try:\n",
    "        while True:\n",
    "            yield sess.run(next_row)\n",
    "\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass\n",
    "\n",
    "    \n",
    "def create_records(ds, record_path):\n",
    "    with tf.Session() as sess, tf.python_io.TFRecordWriter(record_path) as writer:\n",
    "        generator = dataset_generator(ds, sess)\n",
    "        for row in generator:\n",
    "            example = serialize_example(row[0], row[1], row[2], row[3], row[4], row[5])\n",
    "            writer.write(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrecord_name = \"kitti-lf-net.tfrecord\"\n",
    "create_records(features_dataset, tfrecord_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the tfrecord and make sure it is what we expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.TFRecordDataset(tfrecord_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser(serialized):\n",
    "    with tf.name_scope('parse_example'):\n",
    "        example = tf.parse_single_example(serialized, features={\n",
    "            'rgb_fname_1': tf.FixedLenFeature([], tf.string),\n",
    "            'rgb_fname_2': tf.FixedLenFeature([], tf.string),\n",
    "            'depth_fname_1': tf.FixedLenFeature([], tf.string),\n",
    "            'depth_fname_2': tf.FixedLenFeature([], tf.string),\n",
    "            'pose1': tf.FixedLenFeature([16], tf.float32),\n",
    "            'pose2': tf.FixedLenFeature([16], tf.float32),\n",
    "        })\n",
    "    \n",
    "    return example['rgb_fname_1'], example['rgb_fname_2'], example['depth_fname_1'], example['depth_fname_2'], example['pose1'], example['pose2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_dataset = dataset.map(parser)\n",
    "iterator = parsed_dataset.make_one_shot_iterator()\n",
    "\n",
    "data = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(b'kitti_04/dense/images/0000000000.png', b'kitti_04/dense/images/0000000005.png', b'kitti_04/depth/0000000000.png', b'kitti_04/depth/0000000005.png', array([  9.99926388e-01,  -1.00932214e-02,  -6.73365826e-03,\n",
      "         1.33008733e-01,   1.00494931e-02,   9.99928415e-01,\n",
      "        -6.49643084e-03,   1.17375709e-01,   6.79874606e-03,\n",
      "         6.42828271e-03,   9.99956250e-01,  -6.50992203e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "         1.00000000e+00], dtype=float32), array([  9.99865651e-01,  -1.54760154e-02,  -5.40296966e-03,\n",
      "         1.19036116e-01,   1.54497726e-02,   9.99868810e-01,\n",
      "        -4.86540888e-03,   1.02305941e-01,   5.47755836e-03,\n",
      "         4.78128018e-03,   9.99973595e-01,  -6.26558781e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "         1.00000000e+00], dtype=float32))]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    rec = sess.run([data])\n",
    "    print(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
